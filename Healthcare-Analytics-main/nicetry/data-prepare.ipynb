{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加包 \n",
    "抑制报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n",
    "train.Stay.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print(i, ':', train[i].nunique())\n",
    "    \n",
    "# nunique 返回不同值的个数\n",
    "# unique 返回不同值的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of distinct observations in test dataset\n",
    "for i in test.columns:\n",
    "    print(i, ':', test[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bed Grade'].fillna(train['Bed Grade'].mode()[0],inplace=True)\n",
    "test['Bed Grade'].fillna(test['Bed Grade'].mode()[0],inplace=True)\n",
    "\n",
    "train['City_Code_Patient'].fillna(train['City_Code_Patient'].mode()[0], inplace = True)\n",
    "test['City_Code_Patient'].fillna(test['City_Code_Patient'].mode()[0], inplace = True)\n",
    "# mode 众数 \n",
    "# param(true) 默认不考虑缺省值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label encoding Stay column in train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['Stay'] = le.fit_transform(train['Stay'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing dummy Stay column in test datset to concatenate with train dataset\n",
    "test['Stay'] = -1 \n",
    "df = pd.concat([train, test])\n",
    "df.shape\n",
    "\n",
    "# 这里的test以全部都是-1填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding all the columns in Train and test datasets\n",
    "for i in ['Hospital_type_code', 'Hospital_region_code', 'Department',\n",
    "          'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age']:\n",
    "    le = LabelEncoder()\n",
    "    df[i] = le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearating Train and Test Datasets\n",
    "train = df[df['Stay']!=-1]\n",
    "test = df[df['Stay']==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countid_enocde(train, test, cols, name):\n",
    "  temp = train.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "  train = pd.merge(train, temp, how='left', on= cols)\n",
    "  train[name] = train[name].astype('float')\n",
    "  train[name].fillna(np.median(temp[name]), inplace = True)\n",
    "  \n",
    "  temp2 = test.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "  test = pd.merge(test,temp2, how='left', on= cols)\n",
    "  test[name] = test[name].astype('float')\n",
    "  test[name].fillna(np.median(temp2[name]), inplace = True)\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_countid_enocde(train, test, ['patientid'], name = 'count_id_patient')\n",
    "train, test = get_countid_enocde(train, test, \n",
    "                                 ['patientid', 'Hospital_region_code'], name = 'count_id_patient_hospitalCode')\n",
    "train, test = get_countid_enocde(train, test, \n",
    "                                 ['patientid', 'Ward_Facility_Code'], name = 'count_id_patient_wardfacilityCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping duplicate columns\n",
    "test1 = test.drop(['Stay', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis =1)\n",
    "train1 = train.drop(['case_id', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data for Naive Bayes and XGBoost\n",
    "X1 = train1.drop('Stay', axis =1)\n",
    "y1 = train1['Stay']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size =0.20, random_state =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "target = y_train.values\n",
    "features = X_train.values\n",
    "classifier_nb = GaussianNB()\n",
    "model_nb = classifier_nb.fit(features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nb = model_nb.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score_nb = accuracy_score(prediction_nb,y_test)\n",
    "print(\"Acurracy:\", acc_score_nb*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_xgb = xgboost.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=800,\n",
    "                                  objective='multi:softmax', reg_alpha=0.5, reg_lambda=1.5,\n",
    "                                  booster='gbtree', n_jobs=4, min_child_weight=2, base_score= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = classifier_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgb = model_xgb.predict(X_test)\n",
    "acc_score_xgb = accuracy_score(prediction_xgb,y_test)\n",
    "print(\"Accuracy:\", acc_score_xgb*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregation of features and target variable\n",
    "X = train.drop('Stay', axis =1)\n",
    "y = train['Stay']\n",
    "print(X.columns)\n",
    "z = test.drop('Stay', axis = 1)\n",
    "print(z.columns)\n",
    "\n",
    "# Data Scaling\n",
    "from sklearn import preprocessing\n",
    "X_scale = preprocessing.scale(X)\n",
    "X_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size =0.20, random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#Sparse Matrix\n",
    "a = to_categorical(y_train)\n",
    "b = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape = (254750, 20))) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer= 'SGD', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.TensorBoard(\"logs_keras\")]\n",
    "model.fit(X_train, a, epochs=20, callbacks=callbacks, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=(20,)))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer= 'SGD', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(\"logs_keras\")]\n",
    "model.fit(X_train, a, epochs=20, callbacks=callbacks, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining the model with 4 epochs\n",
    "model.fit(X_train, a, epochs=4, validation_split = 0.2)\n",
    "print(\"\\n Model Evaluation\")\n",
    "model.evaluate(X_test,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
