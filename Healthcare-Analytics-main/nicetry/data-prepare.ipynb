{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加包 \n",
    "抑制报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n",
    "train.Stay.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print(i, ':', train[i].nunique())\n",
    "    \n",
    "# nunique 返回不同值的个数\n",
    "# unique 返回不同值的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of distinct observations in test dataset\n",
    "for i in test.columns:\n",
    "    print(i, ':', test[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bed Grade'].fillna(train['Bed Grade'].mode()[0],inplace=True)\n",
    "test['Bed Grade'].fillna(test['Bed Grade'].mode()[0],inplace=True)\n",
    "\n",
    "train['City_Code_Patient'].fillna(train['City_Code_Patient'].mode()[0], inplace = True)\n",
    "test['City_Code_Patient'].fillna(test['City_Code_Patient'].mode()[0], inplace = True)\n",
    "# mode 众数 \n",
    "# param(true) 默认不考虑缺省值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label encoding Stay column in train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['Stay'] = le.fit_transform(train['Stay'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>patientid</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>3</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
       "0        1              8                  c                   3   \n",
       "1        2              2                  c                   5   \n",
       "2        3             10                  e                   1   \n",
       "3        4             26                  b                   2   \n",
       "4        5             26                  b                   2   \n",
       "\n",
       "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
       "0                    Z                                  3  radiotherapy   \n",
       "1                    Z                                  2  radiotherapy   \n",
       "2                    X                                  2    anesthesia   \n",
       "3                    Y                                  2  radiotherapy   \n",
       "4                    Y                                  2  radiotherapy   \n",
       "\n",
       "  Ward_Type Ward_Facility_Code  Bed Grade  patientid  City_Code_Patient  \\\n",
       "0         R                  F        2.0      31397                7.0   \n",
       "1         S                  F        2.0      31397                7.0   \n",
       "2         S                  E        2.0      31397                7.0   \n",
       "3         R                  D        2.0      31397                7.0   \n",
       "4         S                  D        2.0      31397                7.0   \n",
       "\n",
       "  Type of Admission Severity of Illness  Visitors with Patient    Age  \\\n",
       "0         Emergency             Extreme                      2  51-60   \n",
       "1            Trauma             Extreme                      2  51-60   \n",
       "2            Trauma             Extreme                      2  51-60   \n",
       "3            Trauma             Extreme                      2  51-60   \n",
       "4            Trauma             Extreme                      2  51-60   \n",
       "\n",
       "   Admission_Deposit  Stay  \n",
       "0             4911.0     0  \n",
       "1             5954.0     4  \n",
       "2             4745.0     3  \n",
       "3             7272.0     4  \n",
       "4             5558.0     4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
       "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
       "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade',\n",
       "       'patientid', 'City_Code_Patient', 'Type of Admission',\n",
       "       'Severity of Illness', 'Visitors with Patient', 'Age',\n",
       "       'Admission_Deposit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455495, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imputing dummy Stay column in test datset to concatenate with train dataset\n",
    "test['Stay'] = -1 \n",
    "df = pd.concat([train, test])\n",
    "df.shape\n",
    "\n",
    "# 这里的test以全部都是-1填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding all the columns in Train and test datasets\n",
    "for i in ['Hospital_type_code', 'Hospital_region_code', 'Department',\n",
    "          'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age']:\n",
    "    le = LabelEncoder()\n",
    "    df[i] = le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearating Train and Test Datasets\n",
    "train = df[df['Stay']!=-1]\n",
    "test = df[df['Stay']==-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_countid_enocde(train, test, cols, name):\n",
    "  temp = train.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "  train = pd.merge(train, temp, how='left', on= cols)\n",
    "  train[name] = train[name].astype('float')\n",
    "  train[name].fillna(np.median(temp[name]), inplace = True)\n",
    "  \n",
    "  temp2 = test.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "  test = pd.merge(test,temp2, how='left', on= cols)\n",
    "  test[name] = test[name].astype('float')\n",
    "  test[name].fillna(np.median(temp2[name]), inplace = True)\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这个函数的实现需要再确认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_countid_enocde(train, test, ['patientid'], name = 'count_id_patient')\n",
    "train, test = get_countid_enocde(train, test, \n",
    "                                 ['patientid', 'Hospital_region_code'], name = 'count_id_patient_hospitalCode')\n",
    "train, test = get_countid_enocde(train, test, \n",
    "                                 ['patientid', 'Ward_Facility_Code'], name = 'count_id_patient_wardfacilityCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping duplicate columns\n",
    "test1 = test.drop(['Stay', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis =1)\n",
    "train1 = train.drop(['case_id', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data for Naive Bayes and XGBoost\n",
    "X1 = train1.drop('Stay', axis =1)\n",
    "y1 = train1['Stay']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size =0.20, random_state =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "target = y_train.values\n",
    "features = X_train.values\n",
    "classifier_nb = GaussianNB()\n",
    "model_nb = classifier_nb.fit(features, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy: 34.55439015199096\n"
     ]
    }
   ],
   "source": [
    "prediction_nb = model_nb.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score_nb = accuracy_score(prediction_nb,y_test)\n",
    "print(\"Acurracy:\", acc_score_nb*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_xgb = xgboost.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=800,\n",
    "                                  objective='multi:softmax', reg_alpha=0.5, reg_lambda=1.5,\n",
    "                                  booster='gbtree', n_jobs=4, min_child_weight=2, base_score= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = classifier_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.047355859816605\n"
     ]
    }
   ],
   "source": [
    "prediction_xgb = model_xgb.predict(X_test)\n",
    "acc_score_xgb = accuracy_score(prediction_xgb,y_test)\n",
    "print(\"Accuracy:\", acc_score_xgb*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
      "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
      "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade',\n",
      "       'patientid', 'City_Code_Patient', 'Type of Admission',\n",
      "       'Severity of Illness', 'Visitors with Patient', 'Age',\n",
      "       'Admission_Deposit', 'count_id_patient',\n",
      "       'count_id_patient_hospitalCode', 'count_id_patient_wardfacilityCode'],\n",
      "      dtype='object')\n",
      "Index(['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
      "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
      "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade',\n",
      "       'patientid', 'City_Code_Patient', 'Type of Admission',\n",
      "       'Severity of Illness', 'Visitors with Patient', 'Age',\n",
      "       'Admission_Deposit', 'count_id_patient',\n",
      "       'count_id_patient_hospitalCode', 'count_id_patient_wardfacilityCode'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(318438, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segregation of features and target variable\n",
    "X = train.drop('Stay', axis =1)\n",
    "y = train['Stay']\n",
    "print(X.columns)\n",
    "z = test.drop('Stay', axis = 1)\n",
    "print(z.columns)\n",
    "\n",
    "# Data Scaling\n",
    "from sklearn import preprocessing\n",
    "X_scale = preprocessing.scale(X)\n",
    "X_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size =0.20, random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#Sparse Matrix\n",
    "a = to_categorical(y_train)\n",
    "b = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape = (254750, 20))) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 254750, 64)        1344      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 254750, 128)       8320      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 254750, 256)       33024     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 254750, 512)       131584    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 254750, 512)       262656    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 254750, 11)        5643      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 442571 (1.69 MB)\n",
      "Trainable params: 442571 (1.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'SGD', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        actionable for you (your own code).\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        \n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 254750, 20), found shape=(None, 20)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs_keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0te1vf9q.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        \n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        actionable for you (your own code).\n    File \"d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        \n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 254750, 20), found shape=(None, 20)\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(\"logs_keras\")]\n",
    "model.fit(X_train, a, epochs=20, callbacks=callbacks, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=(20,)))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer= 'SGD', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\conda_gpu\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6358/6369 [============================>.] - ETA: 0s - loss: 1.6619 - accuracy: 0.3670WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002F64F5D3880> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000002F64F5D3880>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002F64F5D3880> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x000002F64F5D3880>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6369/6369 [==============================] - 20s 3ms/step - loss: 1.6616 - accuracy: 0.3671 - val_loss: 1.5876 - val_accuracy: 0.3927\n",
      "Epoch 2/20\n",
      "6369/6369 [==============================] - 19s 3ms/step - loss: 1.5700 - accuracy: 0.3985 - val_loss: 1.5628 - val_accuracy: 0.4032\n",
      "Epoch 3/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.5479 - accuracy: 0.4055 - val_loss: 1.5480 - val_accuracy: 0.4089\n",
      "Epoch 4/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.5340 - accuracy: 0.4109 - val_loss: 1.5422 - val_accuracy: 0.4074\n",
      "Epoch 5/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.5245 - accuracy: 0.4140 - val_loss: 1.5392 - val_accuracy: 0.4083\n",
      "Epoch 6/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.5177 - accuracy: 0.4162 - val_loss: 1.5274 - val_accuracy: 0.4143\n",
      "Epoch 7/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.5120 - accuracy: 0.4189 - val_loss: 1.5213 - val_accuracy: 0.4167\n",
      "Epoch 8/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.5072 - accuracy: 0.4199 - val_loss: 1.5228 - val_accuracy: 0.4161\n",
      "Epoch 9/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.5031 - accuracy: 0.4217 - val_loss: 1.5192 - val_accuracy: 0.4179\n",
      "Epoch 10/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.4992 - accuracy: 0.4231 - val_loss: 1.5159 - val_accuracy: 0.4183\n",
      "Epoch 11/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.4960 - accuracy: 0.4245 - val_loss: 1.5193 - val_accuracy: 0.4144\n",
      "Epoch 12/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.4929 - accuracy: 0.4248 - val_loss: 1.5115 - val_accuracy: 0.4208\n",
      "Epoch 13/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.4897 - accuracy: 0.4263 - val_loss: 1.5101 - val_accuracy: 0.4212\n",
      "Epoch 14/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.4872 - accuracy: 0.4266 - val_loss: 1.5178 - val_accuracy: 0.4192\n",
      "Epoch 15/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.4845 - accuracy: 0.4282 - val_loss: 1.5177 - val_accuracy: 0.4192\n",
      "Epoch 16/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.4818 - accuracy: 0.4286 - val_loss: 1.5087 - val_accuracy: 0.4194\n",
      "Epoch 17/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.4793 - accuracy: 0.4308 - val_loss: 1.5097 - val_accuracy: 0.4212\n",
      "Epoch 18/20\n",
      "6369/6369 [==============================] - 17s 3ms/step - loss: 1.4771 - accuracy: 0.4312 - val_loss: 1.5100 - val_accuracy: 0.4201\n",
      "Epoch 19/20\n",
      "6369/6369 [==============================] - 18s 3ms/step - loss: 1.4742 - accuracy: 0.4326 - val_loss: 1.5099 - val_accuracy: 0.4215\n",
      "Epoch 20/20\n",
      "6369/6369 [==============================] - 16s 3ms/step - loss: 1.4723 - accuracy: 0.4321 - val_loss: 1.5103 - val_accuracy: 0.4177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2f64f5ae110>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.TensorBoard(\"logs_keras\")]\n",
    "model.fit(X_train, a, epochs=20, callbacks=callbacks, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6369/6369 [==============================] - 16s 2ms/step - loss: 1.4699 - accuracy: 0.4332 - val_loss: 1.5068 - val_accuracy: 0.4199\n",
      "Epoch 2/4\n",
      "6369/6369 [==============================] - 16s 2ms/step - loss: 1.4677 - accuracy: 0.4336 - val_loss: 1.5053 - val_accuracy: 0.4229\n",
      "Epoch 3/4\n",
      "6369/6369 [==============================] - 15s 2ms/step - loss: 1.4651 - accuracy: 0.4348 - val_loss: 1.5064 - val_accuracy: 0.4218\n",
      "Epoch 4/4\n",
      "6369/6369 [==============================] - 15s 2ms/step - loss: 1.4634 - accuracy: 0.4360 - val_loss: 1.5090 - val_accuracy: 0.4201\n",
      "\n",
      " Model Evaluation\n",
      "1991/1991 [==============================] - 3s 1ms/step - loss: 1.5042 - accuracy: 0.4200\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m test_scale \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mscale(z)\n\u001b[0;32m      9\u001b[0m test_scale\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 11\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(test_scale)\n\u001b[0;32m     12\u001b[0m pred\n\u001b[0;32m     14\u001b[0m result_nn \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(pred, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStay\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "# Retraining the model with 4 epochs\n",
    "model.fit(X_train, a, epochs=4, validation_split = 0.2)\n",
    "print(\"\\n Model Evaluation\")\n",
    "model.evaluate(X_test,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
